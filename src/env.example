# LLM Backend Configuration
# Copy this file to .env and configure your preferred LLM backend

# LLM Backend: choose between "openai", "ollama", "huggingface", or "gemini"
LLM_BACKEND=huggingface

# OpenAI Configuration 
OPENAI_API_KEY=your_openai_api_key_here

# Ollama Configuration (if using Ollama)
OLLAMA_BASE_URL=http://127.0.0.1:11434
OLLAMA_MODEL=llama3.2:3b

# Hugging Face Configuration 
HF_MODEL=meta-llama/Llama-3.2-3B-Instruct
HF_TOKEN=your_huggingface_token_here

# Gemini Configuration
GEMINI_MODEL=gemini-1.5-flash-latest
GEMINI_API_KEY=your_gemini_api_key_here
